import streamlit as st
from model_a_response_qa import get_llm_a_response   # ì—¬ê¸°ì„œëŠ” "ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸ ì…ë ¥ â†’ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥" í•¨ìˆ˜ë¼ê³  ê°€ì •
from model_b_response_qa import get_llm_b_response
import pandas as pd
import json
from datetime import datetime

def run_tab3(switch_tab):
    st.subheader("LLM ê²°ê³¼ ìƒì„±")

    # === í‰ê°€ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° ===
    eval_prompts = st.session_state.get("eval_prompts", None)
    if not eval_prompts:
        st.warning("í‰ê°€ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ìƒ˜í”Œë§' íƒ­ì—ì„œ í‰ê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return

    total = len(eval_prompts)
    st.info(f"í˜„ì¬ ìƒ˜í”Œë§ëœ í‰ê°€ í”„ë¡¬í”„íŠ¸ ê°œìˆ˜: {total}ê°œ")

    # ì˜ˆì‹œ ì¶œë ¥ ê°œìˆ˜ (ìŠ¬ë¼ì´ë”ëŠ” ë§¤ë²ˆ ìƒˆë¡œ ê·¸ë ¤ì ¸ë„ ìƒê´€ ì—†ìŒ)
    num_print = st.slider(
        "ì˜ˆì‹œ ì¶œë ¥ ê°œìˆ˜",
        min_value=1,
        max_value=total,
        value=min(10, total),
        step=1,
        key="tab3_num_print"
    )

    # === ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ===
    if "tab3_df" not in st.session_state:
        st.session_state["tab3_df"] = None
        st.session_state["tab3_df_a"] = None
        st.session_state["tab3_df_b"] = None

    run = st.button("ğŸ” LLM A/B ì‹¤í–‰")

    if run:
        results_a = []
        results_b = []
        with st.spinner("ëª¨ë¸ A/B ì‹¤í–‰ ì¤‘..."):
            # print(eval_prompts)
            for prompt in eval_prompts:
                # print(f"Processing prompt: {prompt}")
                answers_a, a_model_name = get_llm_a_response(prompt)
                answers_b, b_model_name = get_llm_b_response(prompt)
                # print(f"Model A answers: {answers_a}")
                # print(f"Model B answers: {answers_b}")
                results_a.append({"prompt": prompt, "response_a": answers_a})
                results_b.append({"prompt": prompt, "response_b": answers_b})

        # === DataFrame ë³€í™˜ ===
        df_a = pd.DataFrame(results_a)  # columns: prompt, response_a
        df_b = pd.DataFrame(results_b)  # columns: prompt, response_b
        df = pd.merge(df_a, df_b, on="prompt", how="outer")

        st.session_state["tab3_df"] = df
        st.session_state["tab3_df_a"] = df_a
        st.session_state["tab3_df_b"] = df_b

        st.success(f"ìƒì„± ì™„ë£Œ! (ì´ {len(df)}ê°œ)")
    
    a_model_name = "Model A"
    b_model_name = "Model B"
    
    # ì—¬ê¸°ì„œ ì„¸ì…˜ì— ê²°ê³¼ê°€ ì—†ìœ¼ë©´(ì•„ì§ ì‹¤í–‰ ì „ì´ë©´) ê·¸ëƒ¥ ì¢…ë£Œ
    if st.session_state["tab3_df"] is None:
        return

    # === ì„¸ì…˜ì—ì„œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° ===
    df = st.session_state["tab3_df"]
    df_a = st.session_state["tab3_df_a"]
    df_b = st.session_state["tab3_df_b"]

    preview = df.head(int(num_print))

    tab_a, tab_b, tab_merge = st.tabs(["A ê²°ê³¼", "B ê²°ê³¼", "ë³‘í•© ë³´ê¸°"])
    with tab_a:
        st.dataframe(df_a.head(int(num_print)))
    with tab_b:
        st.dataframe(df_b.head(int(num_print)))
    with tab_merge:
        st.dataframe(preview)

    # === ë‹¤ìš´ë¡œë“œìš© ë³€í™˜ ===
    # 1) metadata
    metadata = {
        "A_model_name": f"{a_model_name}",
        "B_model_name": f"{b_model_name}",
        "created_at": datetime.now().isoformat(),
        "num_examples": len(df),
    }

    # 2) models: LLM ì´ë¦„ì„ ì•Œê³  ìˆìœ¼ë©´ ì—¬ê¸° ë„£ì–´ë„ ë¨
    models = [
        {"name": f"{a_model_name}"},   # ì˜ˆ: "MLP-KTLim/llama-3-korean-bllossom-8b"
        {"name": f"{b_model_name}"},   # ì˜ˆ: "LiquidAI/LFM2-2.6B"
    ]

    # 3) examples
    examples = []
    for _, row in df.iterrows():
        examples.append({
            "input_text": row.get("prompt", ""),
            "output_text_a": row.get("response_a", ""),
            "output_text_b": row.get("response_b", ""),
            "score": 0.0,  # ì•„ì§ judgeë¥¼ ì•ˆ í–ˆìœ¼ë‹ˆ 0ìœ¼ë¡œ ë‘ê±°ë‚˜, ë‚˜ì¤‘ì— ê°±ì‹ 
        })

    comparator_payload = {
        "metadata": metadata,
        "models": models,
        "examples": examples,
    }

    comparator_json_bytes = json.dumps(
        comparator_payload,
        ensure_ascii=False,
        indent=2,
    ).encode("utf-8")

    st.session_state["comparator_payload"] = comparator_payload
    # === ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ===
    st.download_button(
        "â¬‡ï¸ LLM Comparator JSON",
        data=comparator_json_bytes,
        file_name="llm_comparator_input.json",
        mime="application/json",
    )

    if st.button("LLM Comparatorë¡œ ì´ë™"):
        switch_tab("LLM Comparator ì‹¤í–‰")
